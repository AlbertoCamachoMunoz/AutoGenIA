<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AutoGen_IA</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/styles.css">
</head>

<body>
    <div class="container text-center">
        <!--  T铆tulo y selector de LLM  -->
        <div class="title">
            <div class="dropdown">
                <button class="menu-btn dropdown-toggle" id="llmDropdown" data-bs-toggle="dropdown"
                    aria-expanded="false">
                    LLM Studio
                </button>
                <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="#" data-llm="llm_studio">LLM Studio</a></li>
                    <!-- a帽ade m谩s modelos aqu铆 -->
                </ul>
            </div>
            <h3 class="mt-4">驴En qu茅 puedo ayudarte?</h3>
        </div>
        <div class="header-buttons header-buttons-vertical">
            <button class="tech-btn info-btn" id="openInfoModal" type="button">
                驴Qu茅 hace el agente?
            </button>
            <button class="tech-btn info-btn" id="openInstructionsModal" type="button">
                驴C贸mo ejecutar la aplicaci贸n?
            </button>
            <button class="tech-btn info-btn" id="openReadmeModal" type="button">
                Arquitectura & README
            </button>
            <button class="tech-btn info-btn" id="openChallengesModal" type="button">
                Retos y Aprendizaje
            </button>
        </div>
        <!--  Input del chat  -->
        <div class="chat-container">
            <input type="text" id="chatInput" class="form-control chat-input" placeholder="" readonly>
        </div>

        <!--  Acciones r谩pidas + descripci贸n  -->
        <div class="quick-actions">
            <p>
                Soy un asistente inteligente capaz de buscar y recopilar productos de la tienda
                (https://www.thefansofmagicstore.com/) online a partir de sus URLs.
                Extraigo precios, descripciones y c贸digos SKU utilizando t茅cnicas avanzadas de scraping web, y presento
                los resultados de forma estructurada y editable.
                Si incluyes una direcci贸n de email en tu consulta, recibir谩s autom谩ticamente la informaci贸n extra铆da
                directamente en tu correo electr贸nico.
            </p>
            <button class="action-btn"
                data-prompt='{ "shops": [{"url": "https://www.thefansofmagicstore.com/", "selector_price":"ins .woocommerce-Price-amount bdi","selector_description":"h3.heading-title.product-name a","selector_sku":{"tag":"a","attribute":"data-product_sku"}}],"langs":[{"lang":"EN"}],"email":"usuario@ejemplo.com"}'>
                 thefansofmagicstore.com
            </button>
        </div>

        <div id="result" class="mt-4"></div>
    </div>


    <!--  Modal de informaci贸n  -->
    <div class="tech-modal-overlay" id="modalOverlay" style="display:none;">
        <div class="tech-modal-content">
            <button class="close-btn" id="closeInfoModal" aria-label="Cerrar">&times;</button>
            <h2>驴Qu茅 tipo de aplicaci贸n es?</h2>
            <p>
                Esta aplicaci贸n es un <strong>Agente Inteligente impulsado por modelos LLM (Large Language
                    Models)</strong> de 煤ltima generaci贸n. Actualmente, utiliza el modelo
                <b>Hermes-2-Pro-Llama-3-8B</b>, que ha sido entrenado para comprender instrucciones complejas y ejecutar
                funciones externas <b>(function calling)</b> de manera aut贸noma.<br><br>
                Permite la interacci贸n conversacional avanzada, as铆 como la automatizaci贸n de procesos como el scraping
                web, procesamiento y formateo de datos, y env铆o de correos electr贸nicos.<br><br>
                El agente puede ejecutarse en local, siendo compatible con plataformas que exponen una API LLM, como
                <b>LM Studio</b> u <b>Ollama</b>.
            </p>
            <h2>驴Qu茅 hace esta aplicaci贸n?</h2>
            <p>
                Esta aplicaci贸n ha sido desarrollada como un sistema profesional de scraping web especializado, con el
                objetivo de demostrar capacidades t茅cnicas avanzadas para procesos automatizados de extracci贸n de
                informaci贸n y env铆o de resultados por correo electr贸nico.<br><br>
                <strong>Actualmente, la aplicaci贸n realiza las siguientes funciones:</strong>
            </p>
            <ul>
                <li>Scrapea la web <a href="https://www.thefansofmagicstore.com" target="_blank" rel="noopener"
                        style="color:#30d2f6;">thefansofmagicstore.com</a> para extraer productos, precios y c贸digos SKU
                    mediante t茅cnicas robustas de an谩lisis estructural HTML.</li>
                <li>Permite visualizar los resultados de forma editable y exportarlos en formato tabla o CSV, simulando
                    una experiencia tipo "Excel" en entorno web.</li>
                <li>Si se proporciona una direcci贸n de correo electr贸nico en la consulta, la informaci贸n extra铆da se
                    env铆a autom谩ticamente por email utilizando un servicio SMTP profesional.</li>
                <li>Actualmente, los emails generados se dirigen a <a href="https://mailtrap.io/" target="_blank"
                        rel="noopener" style="color:#30d2f6;">Mailtrap.io</a>, lo que permite testear el correcto
                    funcionamiento del sistema de env铆o sin afectar a destinatarios reales.</li>
            </ul>
            <p>
                El sistema ha sido dise帽ado para ser f谩cilmente extensible, permitiendo en futuras versiones la
                generalizaci贸n del scraping a cualquier sitio web con configuraciones personalizadas.<br><br>
                <strong>Este proyecto es una demostraci贸n t茅cnica con enfoque profesional, orientada a procesos de
                    automatizaci贸n, extracci贸n masiva de datos y sistemas de mensajer铆a empresarial.</strong>
            </p>
        </div>
    </div>

    <!-- Modal de instrucciones -->
    <div class="tech-modal-overlay" id="instructionsModalOverlay" style="display:none;">
        <div class="tech-modal-content">
            <button class="close-btn" id="closeInstructionsModal" aria-label="Cerrar">&times;</button>
            <h2>Instrucciones de Ejecuci贸n</h2>
            <ol>
                <li>
                    <strong>Ejecutar un servidor LLM compatible:</strong><br>
                    Inicia un servidor de modelos LLM en local utilizando <b>LM Studio</b> o <b>Ollama</b>.
                    Aseg煤rate de que la API est茅 expuesta y accesible desde el sistema donde se despliega la aplicaci贸n.
                </li>
                <li>
                    <strong>Cargar el modelo requerido:</strong><br>
                    Selecciona y carga el modelo <b>Hermes-2-Pro-Llama-3-8B</b> en el servidor LLM.
                    <u>No se garantiza el funcionamiento con otros modelos.</u>
                </li>
                <li>
                    <strong>Configuraci贸n del entorno:</strong><br>
                    Es necesario tener <b>Python 3.10 o superior</b> y <b>pip</b> correctamente instalados.<br>
                    Instala las dependencias ejecutando: <br>
                    <code>pip install -r requirements.txt</code>
                </li>
                <li>
                    <strong>Ejecutar la API Flask:</strong><br>
                    Inicia el backend mediante el comando:<br>
                    <code>python -m presentation.api</code>
                    <br>La aplicaci贸n estar谩 disponible por defecto en <b>http://127.0.0.1:5000</b>
                </li>
                <li>
                    <strong>Configuraci贸n de correo electr贸nico:</strong><br>
                    El sistema est谩 actualmente integrado con <b>Mailtrap.io</b> para pruebas de env铆o de emails.<br>
                    Si deseas utilizar un proveedor SMTP propio, modifica los par谩metros de conexi贸n en la configuraci贸n
                    del backend.
                </li>
            </ol>
            <h3>Requisitos m铆nimos</h3>
            <ul>
                <li>CPU de 4 n煤cleos, 16 GB RAM recomendados para modelos grandes.</li>
                <li>Conexi贸n de red local para la comunicaci贸n entre la aplicaci贸n y el servidor LLM.</li>
                <li>Navegador web moderno (Chrome, Firefox, Edge...)</li>
                <li>Sistema operativo: Windows, Linux o macOS</li>
            </ul>
            <p>
                <b>Nota:</b> El correcto funcionamiento depende de que el modelo est茅 cargado y la API LLM expuesta.<br>
                Para un uso profesional se recomienda equipo con GPU dedicada y conexi贸n segura.
            </p>
        </div>
    </div>
    <div class="tech-modal-overlay" id="readmeModalOverlay" style="display:none;">
        <div class="tech-modal-content readme-style">
            <button class="close-btn" id="closeReadmeModal" aria-label="Cerrar">&times;</button>
            <div id="readmeContent"></div>
        </div>
    </div>

    <div class="tech-modal-overlay" id="challengesModalOverlay" style="display:none;">
        <div class="tech-modal-content" style="max-width: 700px; width: 90vw; min-width:400px;">
            <button class="close-btn" id="closeChallengesModal" aria-label="Cerrar">&times;</button>
            <h2 style="text-align:center; color:#3de2f3; font-weight:800;">Retos y Aprendizaje</h2>
            <blockquote
                style="border-left: 4px solid #3de2f3; background: #26303b; color:#b6ebfa; padding: 1.1em 1.5em; font-size:1.08rem;">
                Implementar una aplicaci贸n basada en agentes LLM AutoGen ha supuesto tanto un <strong>reto
                    t茅cnico</strong> como una gran satisfacci贸n profesional. El proceso no solo ha consistido en
                orquestar agentes inteligentes capaces de ejecutar tareas de scraping, an谩lisis y mensajer铆a, sino en
                integrarlos dentro de una arquitectura <strong>Clean Architecture (Onion)</strong>, empleada en
                proyectos backend robustos, escalables y de mantenimiento sencillo.<br><br>
                Uno de los principales desaf铆os ha sido <strong>seleccionar el modelo LLM adecuado</strong>. No todos
                los modelos actuales son aptos para workflows de function calling avanzado: es fundamental contar con un
                modelo fine-tuned, capaz de comprender, invocar funciones externas y devolver respuestas estructuradas,
                requisitos imprescindibles en sistemas de agentes aut贸nomos.<br><br>
                Otro reto considerable ha sido "domesticar" el modelo para obtener respuestas consistentes y precisas,
                evitando que divague o se salga del flujo funcional previsto. El dise帽o de prompts, el ajuste de los
                flujos de mensajes y el control de los contextos han sido aspectos clave para lograr que el agente
                ejecute sus tareas con fiabilidad y formato profesional.<br><br>
                M谩s all谩 de la parte t茅cnica, la experiencia ha sido un verdadero ejercicio de integraci贸n: desde la
                gesti贸n avanzada de dependencias hasta el dise帽o de sistemas modulares, pasando por la resoluci贸n de
                casos reales de automatizaci贸n, todo ello contribuyendo a ampliar mi expertise en <strong>IA aplicada y
                    arquitecturas modernas para backend</strong>.<br><br>
                En resumen, este proyecto no solo ha supuesto una oportunidad de aprendizaje en el 谩rea de LLM y agentes
                inteligentes, sino que ha reforzado mi capacidad para abordar retos complejos y aportar soluciones
                innovadoras dentro de arquitecturas de alto nivel.
            </blockquote>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="/js/script.js"></script>
</body>

</html>
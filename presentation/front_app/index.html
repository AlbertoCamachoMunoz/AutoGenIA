<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AutoGen_IA</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/styles.css">
</head>

<body>
    <div class="container text-center">
        <!-- ─────────────── Título y selector de LLM ─────────────── -->
        <div class="title">
            <div class="dropdown">
                <button class="menu-btn dropdown-toggle" id="llmDropdown" data-bs-toggle="dropdown"
                    aria-expanded="false">
                    LLM Studio
                </button>
                <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="#" data-llm="llm_studio">LLM Studio</a></li>
                    <!-- añade más modelos aquí -->
                </ul>
            </div>
            <h3 class="mt-4">¿En qué puedo ayudarte?</h3>
        </div>
        <div class="header-buttons header-buttons-vertical">
            <button class="tech-btn info-btn" id="openInfoModal" type="button">
                ¿Qué hace el agente?
            </button>
            <button class="tech-btn info-btn" id="openInstructionsModal" type="button">
                ¿Cómo ejecutar la aplicación?
            </button>
            <button class="tech-btn info-btn" id="openReadmeModal" type="button">
                Arquitectura & README
            </button>
            <button class="tech-btn info-btn" id="openChallengesModal" type="button">
                Retos y Aprendizaje
            </button>
        </div>
        <!-- ─────────────── Input del chat ─────────────── -->
        <div class="chat-container">
            <input type="text" id="chatInput" class="form-control chat-input" placeholder="" readonly>
        </div>

        <!-- ─────────────── Acciones rápidas + descripción ─────────────── -->
        <div class="quick-actions">
            <p>
                Soy un asistente inteligente capaz de buscar y recopilar productos de la tienda
                (https://www.thefansofmagicstore.com/) online a partir de sus URLs.
                Extraigo precios, descripciones y códigos SKU utilizando técnicas avanzadas de scraping web, y presento
                los resultados de forma estructurada y editable.
                Si incluyes una dirección de email en tu consulta, recibirás automáticamente la información extraída
                directamente en tu correo electrónico.
            </p>
            <button class="action-btn"
                data-prompt='{ "shops": [{"url": "https://www.thefansofmagicstore.com/", "selector_price":"ins .woocommerce-Price-amount bdi","selector_description":"h3.heading-title.product-name a","selector_sku":{"tag":"a","attribute":"data-product_sku"}}],"langs":[{"lang":"EN"}],"email":"usuario@ejemplo.com"}'>
                🐍 thefansofmagicstore.com
            </button>
        </div>

        <div id="result" class="mt-4"></div>
    </div>


    <!-- ─────────────── Modal de información ─────────────── -->
    <div class="tech-modal-overlay" id="modalOverlay" style="display:none;">
        <div class="tech-modal-content">
            <button class="close-btn" id="closeInfoModal" aria-label="Cerrar">&times;</button>
            <h2>¿Qué tipo de aplicación es?</h2>
            <p>
                Esta aplicación es un <strong>Agente Inteligente impulsado por modelos LLM (Large Language
                    Models)</strong> de última generación. Actualmente, utiliza el modelo
                <b>Hermes-2-Pro-Llama-3-8B</b>, que ha sido entrenado para comprender instrucciones complejas y ejecutar
                funciones externas <b>(function calling)</b> de manera autónoma.<br><br>
                Permite la interacción conversacional avanzada, así como la automatización de procesos como el scraping
                web, procesamiento y formateo de datos, y envío de correos electrónicos.<br><br>
                El agente puede ejecutarse en local, siendo compatible con plataformas que exponen una API LLM, como
                <b>LM Studio</b> u <b>Ollama</b>.
            </p>
            <h2>¿Qué hace esta aplicación?</h2>
            <p>
                Esta aplicación ha sido desarrollada como un sistema profesional de scraping web especializado, con el
                objetivo de demostrar capacidades técnicas avanzadas para procesos automatizados de extracción de
                información y envío de resultados por correo electrónico.<br><br>
                <strong>Actualmente, la aplicación realiza las siguientes funciones:</strong>
            </p>
            <ul>
                <li>Scrapea la web <a href="https://www.thefansofmagicstore.com" target="_blank" rel="noopener"
                        style="color:#30d2f6;">thefansofmagicstore.com</a> para extraer productos, precios y códigos SKU
                    mediante técnicas robustas de análisis estructural HTML.</li>
                <li>Permite visualizar los resultados de forma editable y exportarlos en formato tabla o CSV, simulando
                    una experiencia tipo "Excel" en entorno web.</li>
                <li>Si se proporciona una dirección de correo electrónico en la consulta, la información extraída se
                    envía automáticamente por email utilizando un servicio SMTP profesional.</li>
                <li>Actualmente, los emails generados se dirigen a <a href="https://mailtrap.io/" target="_blank"
                        rel="noopener" style="color:#30d2f6;">Mailtrap.io</a>, lo que permite testear el correcto
                    funcionamiento del sistema de envío sin afectar a destinatarios reales.</li>
            </ul>
            <p>
                El sistema ha sido diseñado para ser fácilmente extensible, permitiendo en futuras versiones la
                generalización del scraping a cualquier sitio web con configuraciones personalizadas.<br><br>
                <strong>Este proyecto es una demostración técnica con enfoque profesional, orientada a procesos de
                    automatización, extracción masiva de datos y sistemas de mensajería empresarial.</strong>
            </p>
        </div>
    </div>

    <!-- Modal de instrucciones -->
    <div class="tech-modal-overlay" id="instructionsModalOverlay" style="display:none;">
        <div class="tech-modal-content">
            <button class="close-btn" id="closeInstructionsModal" aria-label="Cerrar">&times;</button>
            <h2>Instrucciones de Ejecución</h2>
            <ol>
                <li>
                    <strong>Ejecutar un servidor LLM compatible:</strong><br>
                    Inicia un servidor de modelos LLM en local utilizando <b>LM Studio</b> o <b>Ollama</b>.
                    Asegúrate de que la API esté expuesta y accesible desde el sistema donde se despliega la aplicación.
                </li>
                <li>
                    <strong>Cargar el modelo requerido:</strong><br>
                    Selecciona y carga el modelo <b>Hermes-2-Pro-Llama-3-8B</b> en el servidor LLM.
                    <u>No se garantiza el funcionamiento con otros modelos.</u>
                </li>
                <li>
                    <strong>Configuración del entorno:</strong><br>
                    Es necesario tener <b>Python 3.10 o superior</b> y <b>pip</b> correctamente instalados.<br>
                    Instala las dependencias ejecutando: <br>
                    <code>pip install -r requirements.txt</code>
                </li>
                <li>
                    <strong>Ejecutar la API Flask:</strong><br>
                    Inicia el backend mediante el comando:<br>
                    <code>python -m presentation.api</code>
                    <br>La aplicación estará disponible por defecto en <b>http://127.0.0.1:5000</b>
                </li>
                <li>
                    <strong>Configuración de correo electrónico:</strong><br>
                    El sistema está actualmente integrado con <b>Mailtrap.io</b> para pruebas de envío de emails.<br>
                    Si deseas utilizar un proveedor SMTP propio, modifica los parámetros de conexión en la configuración
                    del backend.
                </li>
            </ol>
            <h3>Requisitos mínimos</h3>
            <ul>
                <li>CPU de 4 núcleos, 16 GB RAM recomendados para modelos grandes.</li>
                <li>Conexión de red local para la comunicación entre la aplicación y el servidor LLM.</li>
                <li>Navegador web moderno (Chrome, Firefox, Edge...)</li>
                <li>Sistema operativo: Windows, Linux o macOS</li>
            </ul>
            <p>
                <b>Nota:</b> El correcto funcionamiento depende de que el modelo esté cargado y la API LLM expuesta.<br>
                Para un uso profesional se recomienda equipo con GPU dedicada y conexión segura.
            </p>
        </div>
    </div>
    <div class="tech-modal-overlay" id="readmeModalOverlay" style="display:none;">
        <div class="tech-modal-content readme-style">
            <button class="close-btn" id="closeReadmeModal" aria-label="Cerrar">&times;</button>
            <div id="readmeContent"></div>
        </div>
    </div>

    <div class="tech-modal-overlay" id="challengesModalOverlay" style="display:none;">
        <div class="tech-modal-content" style="max-width: 700px; width: 90vw; min-width:400px;">
            <button class="close-btn" id="closeChallengesModal" aria-label="Cerrar">&times;</button>
            <h2 style="text-align:center; color:#3de2f3; font-weight:800;">Retos y Aprendizaje</h2>
            <blockquote
                style="border-left: 4px solid #3de2f3; background: #26303b; color:#b6ebfa; padding: 1.1em 1.5em; font-size:1.08rem;">
                Implementar una aplicación basada en agentes LLM AutoGen ha supuesto tanto un <strong>reto
                    técnico</strong> como una gran satisfacción profesional. El proceso no solo ha consistido en
                orquestar agentes inteligentes capaces de ejecutar tareas de scraping, análisis y mensajería, sino en
                integrarlos dentro de una arquitectura <strong>Clean Architecture (Onion)</strong>, empleada en
                proyectos backend robustos, escalables y de mantenimiento sencillo.<br><br>
                Uno de los principales desafíos ha sido <strong>seleccionar el modelo LLM adecuado</strong>. No todos
                los modelos actuales son aptos para workflows de function calling avanzado: es fundamental contar con un
                modelo fine-tuned, capaz de comprender, invocar funciones externas y devolver respuestas estructuradas,
                requisitos imprescindibles en sistemas de agentes autónomos.<br><br>
                Otro reto considerable ha sido "domesticar" el modelo para obtener respuestas consistentes y precisas,
                evitando que divague o se salga del flujo funcional previsto. El diseño de prompts, el ajuste de los
                flujos de mensajes y el control de los contextos han sido aspectos clave para lograr que el agente
                ejecute sus tareas con fiabilidad y formato profesional.<br><br>
                Más allá de la parte técnica, la experiencia ha sido un verdadero ejercicio de integración: desde la
                gestión avanzada de dependencias hasta el diseño de sistemas modulares, pasando por la resolución de
                casos reales de automatización, todo ello contribuyendo a ampliar mi expertise en <strong>IA aplicada y
                    arquitecturas modernas para backend</strong>.<br><br>
                En resumen, este proyecto no solo ha supuesto una oportunidad de aprendizaje en el área de LLM y agentes
                inteligentes, sino que ha reforzado mi capacidad para abordar retos complejos y aportar soluciones
                innovadoras dentro de arquitecturas de alto nivel.
            </blockquote>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="/js/script.js"></script>
</body>

</html>